{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Traveling Salesman Problem (DTSP) with RL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TSP Environment using Gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from copy import copy, deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# Logs for graphs about the training progress\n",
    "steps_log = [class TSPEnv(gym.Env):\n",
    "    '''\n",
    "    Bi-directional connections and uniform cost\n",
    "\n",
    "    This version of the TSP uses a sparse graph with uniform cost.\n",
    "    The goal is to minimize the cost to traverse all of the nodes in the\n",
    "    network. All connections are bi-directional meaning if a connection\n",
    "    between nodes n and m exist, then the agent can move in either direction.\n",
    "    The network is randomly generated with N nodes when the environment is\n",
    "    initialized using or_gym.make(). \n",
    "    \n",
    "    TSP-v0 allows repeat visits to nodes with no additional penalty beyond\n",
    "    the nominal movement cost.\n",
    "\n",
    "    Observation:\n",
    "        \n",
    "\n",
    "    Actions:\n",
    "        Type: Discrete\n",
    "        0: move to node 0\n",
    "        1: move to node 1\n",
    "        2: ...\n",
    "\n",
    "    Action Masking (optional):\n",
    "        Masks non-existent connections, otherwise a large penalty is imposed\n",
    "        on the agent.\n",
    "\n",
    "    Reward:\n",
    "        Cost of moving from node to node or large negative penalty for\n",
    "        attempting to move to a node via a non-existent connection.\n",
    "\n",
    "    Starting State:\n",
    "        Random node\n",
    "\n",
    "    Episode Termination:\n",
    "        All nodes have been visited or the maximimum number of steps (2N)\n",
    "        have been reached.\n",
    "    '''\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.N = 7\n",
    "        self.dist_factor = 3\n",
    "        self.move_cost = -1\n",
    "        self.invalid_action_cost = -100\n",
    "        self.mask = False\n",
    "        self.spec = SimpleNamespace(reward_threshold=1000)\n",
    "        self.render_ready = False\n",
    "\n",
    "        self.locations = []\n",
    "        self.min_dist = -1\n",
    "        self.step_count = 0\n",
    "        self.nodes = np.arange(self.N)\n",
    "        self.step_limit = 2*self.N\n",
    "        self.obs_dim = 1+self.N**2\n",
    "        # obs_space = spaces.Box(-1, self.N, shape=(self.obs_dim,), dtype=np.int32)\n",
    "        self.observation_space = spaces.MultiDiscrete([self.N+1] + [2]*self.N + [200]*(self.N**2))\n",
    "        # Example: [ 0  1  0  0  0  0  0 54 77 94 79 54  0 23 40 41 77 23  0 17 28 94 40 17 0 27 79 41 28 27  0]\n",
    "        # print(self.observation_space)\n",
    "\n",
    "        self.action_space = spaces.Discrete(self.N)\n",
    "        self.path = []\n",
    "        self.dist_sum = 0\n",
    "        self.reset()\n",
    "        \n",
    "    def _STEP(self, action):\n",
    "        done = False\n",
    "        self.path.append(action)\n",
    "        # Todo: reward based on comparison to minimum path instead of absolute distance (varies too much)\n",
    "        dist = np.sqrt(self._node_sqdist(self.current_node, action)) / self.min_dist\n",
    "        # dist = self._node_dist_manhattan(self.current_node, action) / self.min_dist\n",
    "        self.dist_sum += dist\n",
    "        reward = -dist * self.dist_factor\n",
    "        # reward = 0\n",
    "        # print(f\"From: {self.current_node}; To: {action}; Cost: {reward}; Stall? {action == self.current_node}; Repeat? {self.visit_log[action] > 1}\")\n",
    "        # print(f\"Sub: {reward}\")\n",
    "        if action == self.current_node:\n",
    "            # print('stall')\n",
    "            reward -= 100\n",
    "        if self.visit_log[action] >= 1:\n",
    "            # print('repeat')\n",
    "            reward -= 100\n",
    "        # print(f\"subtracting {reward}\")\n",
    "        self.current_node = action\n",
    "        # print(action)\n",
    "        if self.visit_log[self.current_node] == 0:\n",
    "            # print('new node')\n",
    "            reward += 100\n",
    "        self.visit_log[self.current_node] += 1\n",
    "            \n",
    "        self.state = self._update_state()\n",
    "        self.step_count += 1\n",
    "        # See if all nodes have been visited\n",
    "        unique_visits = sum([1 if v > 0 else 0 \n",
    "            for v in self.visit_log.values()])\n",
    "        if unique_visits >= self.N:\n",
    "            self.path.append(self.path[0])\n",
    "            dist = np.sqrt(self._node_sqdist(self.current_node, action))\n",
    "            self.dist_sum += dist\n",
    "            reward -= dist * self.dist_factor\n",
    "            done = True\n",
    "            reward += 500\n",
    "        if self.step_count >= self.step_limit:\n",
    "            done = True\n",
    "            \n",
    "        if done and self.render_ready:\n",
    "            print(f\"Locations: {self.locations}\")\n",
    "            print(f\"Path: {self.path}\")\n",
    "            fig, ax = plt.subplots(figsize=(12,8))\n",
    "            for n in range(self.N):\n",
    "                pt = self.locations[n]\n",
    "                clr = 'green' if n == 0 else 'black'\n",
    "                ax.scatter(pt[0], pt[1], color=clr, s=300)\n",
    "                ax.annotate(r\"$N_{:d}$\".format(n), xy=(pt[0]+0.4, pt[1]+0.05), zorder=2)\n",
    "            for i in range(len(self.path) - 1):\n",
    "                ax.plot([self.locations[self.path[i]][0], self.locations[self.path[i+1]][0]],\n",
    "                    [self.locations[self.path[i]][1], self.locations[self.path[i+1]][1]], 'bo', linestyle='solid')\n",
    "            current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "            fig.savefig(f\"{self.N}-solution-{current_datetime}.png\")\n",
    "        return self.state, reward, done, (self.step_count >= self.step_limit), {}\n",
    "    \n",
    "    def _node_dist(self, a, b):\n",
    "        return np.sqrt(self._node_sqdist(a, b))\n",
    "\n",
    "    def _node_dist_manhattan(self, a, b):\n",
    "        apt = self.locations[a]\n",
    "        bpt = self.locations[b]\n",
    "        dx = apt[0] - bpt[0]\n",
    "        dy = apt[1] - bpt[1]\n",
    "        return abs(dx) + abs(dy)\n",
    "\n",
    "\n",
    "    def _node_sqdist(self, a, b):\n",
    "        apt = self.locations[a]\n",
    "        bpt = self.locations[b]\n",
    "        dx = apt[0] - bpt[0]\n",
    "        dy = apt[1] - bpt[1]\n",
    "        return dx*dx + dy*dy\n",
    "\n",
    "    def _RESET(self):\n",
    "        if self.step_count > 0:\n",
    "            steps_log.append(self.step_count)\n",
    "            if self.step_count < 10:\n",
    "                solved_log.append(1)\n",
    "                dist_log.append(self.dist_sum)\n",
    "            else:\n",
    "                dist_log.append(1000)\n",
    "                solved_log.append(0)\n",
    "        self.step_count = 0\n",
    "        self.dist_sum = 0\n",
    "        self.current_node = np.random.choice(self.nodes)\n",
    "        self.visit_log = {n: 0 for n in self.nodes}\n",
    "        self.visit_log[self.current_node] += 1\n",
    "        self._generate_locations()\n",
    "        self.path = [self.current_node]\n",
    "        self.state = self._update_state()\n",
    "        return self.state, {}\n",
    "        \n",
    "    def _generate_locations(self):\n",
    "        self.locations.clear()\n",
    "        for i in range(self.N):\n",
    "            self.locations.append((np.random.randint(0,100), np.random.randint(0,100)))\n",
    "        self.min_dist = self.find_min_dist([self.current_node])\n",
    "        # print(f\"Min dist: {self.min_dist}\")\n",
    "        \n",
    "\n",
    "    def _update_state(self):\n",
    "        visit_list = [min(self.visit_log[i], 1) for i in range(self.N)]\n",
    "        dist_matrix = self.generate_1d_distance_matrix()\n",
    "        state = np.array([self.current_node] + visit_list + dist_matrix)\n",
    "        # print(f'state: {state}')\n",
    "        return state\n",
    "            \n",
    "    def generate_1d_distance_matrix(self):\n",
    "        matrix = []\n",
    "        # max_dist = 100 * np.sqrt(2)\n",
    "        for i in range(self.N):\n",
    "            for j in range(self.N):\n",
    "                matrix.append(self._node_dist_manhattan(i, j))\n",
    "        # print(f\"matrix: {matrix}\")\n",
    "        return matrix\n",
    "\n",
    "    def _generate_coordinates(self):\n",
    "        n = np.linspace(0, 2*np.pi, self.N+1)\n",
    "        x = np.cos(n)\n",
    "        y = np.sin(n)\n",
    "        return np.vstack([x, y])\n",
    "\n",
    "    def _get_node_distance(self, N0, N1):\n",
    "        return np.sqrt(np.power(N0[0] - N1[0], 2) + np.power(N0[1] - N1[1], 2))\n",
    "            \n",
    "    def step(self, action):\n",
    "        if self.render_ready:\n",
    "            print(f\"moving to {action}\")\n",
    "        return self._STEP(action)\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        return self._RESET()\n",
    "    \n",
    "    def render(self):\n",
    "        if not self.render_ready:\n",
    "            self.render_ready = True\n",
    "\n",
    "    def find_min_dist(self, arr):\n",
    "        low = 9999999\n",
    "        low_i = -1\n",
    "        unique = 0\n",
    "        for i in range(self.N):\n",
    "            if arr.count(i) == 0:\n",
    "                md = self.find_min_dist(arr + [i]) + self._node_dist_manhattan(arr[-1], i) #np.sqrt(self._node_sqdist(arr[-1], i))\n",
    "                # if md == 0:\n",
    "                #     print(f'arr: {arr}, i: {i}, md: {md}')\n",
    "                if md < low:\n",
    "                    low = md\n",
    "                    low_i = i\n",
    "            else:\n",
    "                unique += 1\n",
    "        if unique == self.N:\n",
    "            # print(f'min path: {arr}')\n",
    "            # return np.sqrt(self._node_sqdist(arr[-1] ,arr[0]))\n",
    "            return self._node_dist_manhattan(arr[-1], arr[0])\n",
    "        return low\n",
    "                \n",
    "\n",
    "def save_steps_log():\n",
    "    # print(steps_log)\n",
    "    avgs = []\n",
    "    num_pts = 100\n",
    "    for i in range(num_pts):\n",
    "        sum = 0\n",
    "        for i in range(len(steps_log)//num_pts * i, len(steps_log)//num_pts * (i+1)):\n",
    "            sum += steps_log[i]\n",
    "        avgs.append(sum / (len(steps_log) // num_pts))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(range(num_pts), avgs)\n",
    "    fig.savefig('steps_log.png')\n",
    "\n",
    "def save_dist_log():\n",
    "    # print(steps_log)\n",
    "    avgs = []\n",
    "    num_pts = 100\n",
    "    for i in range(num_pts):\n",
    "        sum = 0\n",
    "        for i in range(len(dist_log)//num_pts * i, len(dist_log)//num_pts * (i+1)):\n",
    "            sum += dist_log[i]\n",
    "        avgs.append(sum / (len(dist_log) // num_pts))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(range(num_pts), avgs)\n",
    "    fig.savefig('dist_log.png')\n",
    "\n",
    "def save_solved_log():\n",
    "    # print(steps_log)\n",
    "    avgs = []\n",
    "    num_pts = 100\n",
    "    for i in range(num_pts):\n",
    "        sum = 0\n",
    "        for i in range(len(solved_log)//num_pts * i, len(solved_log)//num_pts * (i+1)):\n",
    "            sum += solved_log[i]\n",
    "        avgs.append(sum / (len(solved_log) // num_pts))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(range(num_pts), avgs)\n",
    "    fig.savefig('solved_log.png')]\n",
    "dist_log = []\n",
    "solved_log = []\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
